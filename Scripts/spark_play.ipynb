{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as fn\n",
    "\n",
    "\n",
    "#from pyspark.mllib.util import MLUtils\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel, Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "\n",
    "sc = pyspark.SparkContext()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSchema = StructType([\n",
    "        StructField(\"textID\",StringType(),True),\n",
    "        StructField(\"ID(seq)\",StringType(),True),\n",
    "        StructField(\"word\",StringType(),True),\n",
    "        StructField(\"lemma\",StringType(),True),\n",
    "        StructField(\"PoS\",StringType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../SampleData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAll  = spark.read.option('delimiter', '\\t').csv(path=DATA_DIR+'us_mini.txt', schema=dataSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+--------+------+\n",
      "|  textID|   ID(seq)|      word|   lemma|   PoS|\n",
      "+--------+----------+----------+--------+------+\n",
      "|14637197|4739839025|@@14637197|    null|    fo|\n",
      "|14637197|4739839026|       <p>|    null|  null|\n",
      "|14637197|4739839027|       NEW|     new|   np1|\n",
      "|14637197|4739839028|      YORK|    york|   np1|\n",
      "|14637197|4739839029|         (|    null|     (|\n",
      "|14637197|4739839030|        AP|      ap|   np1|\n",
      "|14637197|4739839031|         )|    null|     )|\n",
      "|14637197|4739839032|        --|    null|jj_nn1|\n",
      "|14637197|4739839033|    Donald|  donald|   np1|\n",
      "|14637197|4739839034|     Trump|   trump|   nn1|\n",
      "|14637197|4739839035|        's|      's|    ge|\n",
      "|14637197|4739839036|  five-day|five-day|    jj|\n",
      "|14637197|4739839037|      feud|    feud|   nn1|\n",
      "|14637197|4739839038|      with|    with|    iw|\n",
      "|14637197|4739839039|         a|       a|   at1|\n",
      "|14637197|4739839040|    former|  former|    da|\n",
      "|14637197|4739839041|    beauty|  beauty|   nn1|\n",
      "|14637197|4739839042|     queen|   queen|   nn1|\n",
      "|14637197|4739839043|        is|      be|   vbz|\n",
      "|14637197|4739839044|      only|    only|    rr|\n",
      "+--------+----------+----------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataAll.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.select(df.columns[['textID','lemma']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = dataAll['textID','lemma'].na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pll = data_all.toPandas()\n",
    "# pll.lemma.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_g = data_all.groupby(\"textID\").agg(fn.collect_list(\"lemma\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|  textID| collect_list(lemma)|\n",
      "+--------+--------------------+\n",
      "|14637197|[new, york, ap, d...|\n",
      "|14637202|[in, this, sept, ...|\n",
      "|14637201|[another, hotel, ...|\n",
      "|14637200|[here, be, all, t...|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_all_g.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"collect_list(lemma)\", outputCol=\"vectors\")\n",
    "cv_model = cv.fit(data_all_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|  textID| collect_list(lemma)|             vectors|\n",
      "+--------+--------------------+--------------------+\n",
      "|14637197|[new, york, ap, d...|(438,[0,1,2,3,4,5...|\n",
      "|14637202|[in, this, sept, ...|(438,[0,1,2,3,4,5...|\n",
      "|14637201|[another, hotel, ...|(438,[0,1,2,3,4,5...|\n",
      "|14637200|[here, be, all, t...|(438,[0,1,2,3,4,5...|\n",
      "+--------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_all_v = cv_model.transform(data_all_g)\n",
    "data_all_v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20 = list(cv_model.vocabulary[0:20])\n",
    "more_then_3_charachters = [word for word in cv_model.vocabulary if len(word) <= 3]\n",
    "contains_digits = [word for word in cv_model.vocabulary if any(char.isdigit() for char in word)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []  #Add additional stopwords in this list\n",
    "default_stop = StopWordsRemover.loadDefaultStopWords('english')\n",
    "#Combine the three stopwords\n",
    "stopwords = stopwords + top20  + more_then_3_charachters + contains_digits + default_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords from the tokenized list\n",
    "remover = StopWordsRemover(inputCol=\"collect_list(lemma)\", outputCol=\"filtered\", stopWords = stopwords)\n",
    "data_all_filtered = remover.transform(data_all_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|  textID| collect_list(lemma)|            filtered|\n",
      "+--------+--------------------+--------------------+\n",
      "|14637197|[new, york, ap, d...|[york, donald, tr...|\n",
      "|14637202|[in, this, sept, ...|[sept, photo, ric...|\n",
      "|14637201|[another, hotel, ...|[another, hotel, ...|\n",
      "|14637200|[here, be, all, t...|[crazy, stuff, ha...|\n",
      "+--------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_all_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new CountVectorizer model without the stopwords\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"vectors\")\n",
    "cvmodel = cv.fit(data_all_filtered)\n",
    "df_vect = cvmodel.transform(data_all_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|  textID| collect_list(lemma)|            filtered|             vectors|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "|14637197|[new, york, ap, d...|[york, donald, tr...|(315,[5,8,11,12,1...|\n",
      "|14637202|[in, this, sept, ...|[sept, photo, ric...|(315,[2,4,7,9,13,...|\n",
      "|14637201|[another, hotel, ...|[another, hotel, ...|(315,[3,6,17,18,1...|\n",
      "|14637200|[here, be, all, t...|[crazy, stuff, ha...|(315,[0,1,8,10,13...|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vect.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the dataframe to a format that can be used as input for LDA.train. LDA train expects a RDD with lists,\n",
    "#where the list consists of a uid and (sparse) Vector\n",
    "def parseVectors(line):\n",
    "    return [int(line[2]), line[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|  textID| collect_list(lemma)|            filtered|             vectors|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "|14637197|[new, york, ap, d...|[york, donald, tr...|(315,[5,8,11,12,1...|\n",
      "|14637202|[in, this, sept, ...|[sept, photo, ric...|(315,[2,4,7,9,13,...|\n",
      "|14637201|[another, hotel, ...|[another, hotel, ...|(315,[3,6,17,18,1...|\n",
      "|14637200|[here, be, all, t...|[crazy, stuff, ha...|(315,[0,1,8,10,13...|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vect.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel, Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors, SparseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseData = df_vect.select('textID','vectors').rdd.map(lambda x: [int(x[0]), Vectors.sparse(x[1])] ) #.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelinedRDD' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-ae3b3461266e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparseData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'PipelinedRDD' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "parseData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(k=10, maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelinedRDD' object has no attribute '_jdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-dbe77137d2ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparseData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PipelinedRDD' object has no attribute '_jdf'"
     ]
    }
   ],
   "source": [
    "lda.fit(parseData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parseData.registerTempTable('parseData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import sql\n",
    "\n",
    "sqlContext = sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsevector = df_vect.select('vectors', 'filtered', 'textID') #.map(parseVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors, SparseVector\n",
    "# data = [[1, Vectors.dense([0.0, 1.0])],[2, SparseVector(2, {0: 1.0})],]\n",
    "# rdd =  sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distribu;tions over vocab of 11 words):\n",
      "Topic 0:\n",
      " 8.15582005442717\n",
      " 10.656943075611748\n",
      " 3.855385888247155\n",
      " 6.040492015211564\n",
      " 5.650997868296005\n",
      " 9.44768518707235\n",
      " 21.145627148673356\n",
      " 2.4724284854156613\n",
      " 2.601081411159921\n",
      " 10.144900085534445\n",
      " 6.875519127498014\n",
      "Topic 1:\n",
      " 9.441854988623765\n",
      " 6.350068100696127\n",
      " 1.5408204958934313\n",
      " 9.778830398980592\n",
      " 10.950042790661328\n",
      " 8.675691428171943\n",
      " 5.864832561565598\n",
      " 5.287038760035064\n",
      " 3.2741848108201212\n",
      " 6.9649099138112\n",
      " 18.086982260006085\n",
      "Topic 2:\n",
      " 8.402324956949066\n",
      " 11.992988823692123\n",
      " 6.603793615859415\n",
      " 24.180677585807846\n",
      " 8.398959341042666\n",
      " 3.8766233847557072\n",
      " 3.9895402897610457\n",
      " 2.240532754549275\n",
      " 2.124733778019957\n",
      " 6.890190000654354\n",
      " 8.037498612495902\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o238.save.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/ezgi/Desktop/ADA/NewsCorpus/repo/Scripts/target/org/apache/spark/PythonLatentDirichletAllocationExample/LDAModel/metadata already exists\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:283)\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1493)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1472)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1472)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1472)\n\tat org.apache.spark.mllib.clustering.DistributedLDAModel$SaveLoadV1_0$.save(LDAModel.scala:876)\n\tat org.apache.spark.mllib.clustering.DistributedLDAModel.save(LDAModel.scala:819)\n\tat org.apache.spark.mllib.api.python.LDAModelWrapper.save(LDAModelWrapper.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7184449bc034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Save and load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mldaModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target/org/apache/spark/PythonLatentDirichletAllocationExample/LDAModel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0msameModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDAModel\u001b[0m    \u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target/org/apache/spark/PythonLatentDirichletAllocationExample/LDAModel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/mllib/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sc, path)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path should be a basestring, got type %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o238.save.\n: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/ezgi/Desktop/ADA/NewsCorpus/repo/Scripts/target/org/apache/spark/PythonLatentDirichletAllocationExample/LDAModel/metadata already exists\n\tat org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)\n\tat org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:283)\n\tat org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1493)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1472)\n\tat org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1472)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n\tat org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1472)\n\tat org.apache.spark.mllib.clustering.DistributedLDAModel$SaveLoadV1_0$.save(LDAModel.scala:876)\n\tat org.apache.spark.mllib.clustering.DistributedLDAModel.save(LDAModel.scala:819)\n\tat org.apache.spark.mllib.api.python.LDAModelWrapper.save(LDAModelWrapper.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# Load and parse the data\n",
    "data = sc.textFile(\"data/sample_lda_data.txt\")\n",
    "parsedData = data.map(lambda line: Vectors.dense([float(x) for x in line.strip().split(' ')]))\n",
    "# Index documents with unique IDs\n",
    "corpus = parsedData.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()\n",
    "\n",
    "# Cluster the documents into three topics using LDA\n",
    "ldaModel = LDA.train(corpus, k=3)\n",
    "\n",
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distribu;tions over vocab of \" + str(ldaModel.vocabSize())\n",
    "      + \" words):\")\n",
    "topics = ldaModel.topicsMatrix()\n",
    "for topic in range(3):\n",
    "    print(\"Topic \" + str(topic) + \":\")\n",
    "    for word in range(0, ldaModel.vocabSize()):\n",
    "        print(\" \" + str(topics[word][topic]))\n",
    "\n",
    "# Save and load model\n",
    "ldaModel.save(sc, \"target/org/apache/spark/PythonLatentDirichletAllocationExample/LDAModel\")\n",
    "sameModel = LDAModel\\\n",
    "    .load(sc, \"target/org/apache/spark/PythonLatentDirichletAllocationExample/LDAModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, DenseVector([1.0, 2.0, 6.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 3.0])],\n",
       " [1, DenseVector([1.0, 3.0, 0.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0])],\n",
       " [2, DenseVector([1.0, 4.0, 1.0, 0.0, 0.0, 4.0, 9.0, 0.0, 1.0, 2.0, 0.0])],\n",
       " [3, DenseVector([2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 5.0, 0.0, 2.0, 3.0, 9.0])],\n",
       " [4, DenseVector([3.0, 1.0, 1.0, 9.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 3.0])],\n",
       " [5, DenseVector([4.0, 2.0, 0.0, 3.0, 4.0, 5.0, 1.0, 1.0, 1.0, 4.0, 0.0])],\n",
       " [6, DenseVector([2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 5.0, 0.0, 2.0, 2.0, 9.0])],\n",
       " [7, DenseVector([1.0, 1.0, 1.0, 9.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0])],\n",
       " [8, DenseVector([4.0, 4.0, 0.0, 3.0, 4.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0])],\n",
       " [9, DenseVector([2.0, 8.0, 2.0, 0.0, 3.0, 0.0, 2.0, 0.0, 2.0, 7.0, 2.0])],\n",
       " [10, DenseVector([1.0, 1.0, 1.0, 9.0, 0.0, 2.0, 2.0, 0.0, 0.0, 3.0, 3.0])],\n",
       " [11, DenseVector([4.0, 1.0, 0.0, 0.0, 4.0, 5.0, 1.0, 3.0, 0.0, 1.0, 0.0])]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|  textID| collect_list(lemma)|            filtered|             vectors|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "|14637197|[new, york, ap, d...|[york, donald, tr...|(314,[4,5,8,11,19...|\n",
      "|14637202|[in, this, sept, ...|[sept, photo, ric...|(314,[1,3,7,10,15...|\n",
      "|14637201|[another, hotel, ...|[another, hotel, ...|(314,[2,14,16,18,...|\n",
      "|14637200|[here, be, all, t...|[crazy, stuff, ha...|(314,[0,5,6,9,10,...|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vect.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseData = df_vect.select('textID','vectors').rdd.map(lambda x: [int(x[0]), Vectors.dense(x[1])] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaModel = LDA.train(parseData, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distribu;tions over vocab of 314 words):\n",
      "Topic 0:\n",
      " 3.9704595682608885\n",
      " 0.02312037932725725\n",
      " 3.90595140113783\n",
      " 0.023120452870414258\n",
      " 0.01972778996220793\n",
      " 2.0369844612066887\n",
      " 2.9707684611354175\n",
      " 0.02288816952648734\n",
      " 0.019535498897296895\n",
      " 2.9707795102163557\n",
      " 2.0995037488636528\n",
      " 0.019535498881077598\n",
      " 2.970785959735581\n",
      " 2.9707690597089096\n",
      " 2.9075029688966096\n",
      " 0.02288850041655209\n",
      " 2.9074694284330835\n",
      " 2.970775091173252\n",
      " 2.907454359187454\n",
      " 1.4837181865838622\n",
      " 0.022435483137319155\n",
      " 0.9363735375394422\n",
      " 1.9713957555515416\n",
      " 0.49595815146467526\n",
      " 1.9104723505664165\n",
      " 1.9104741406398098\n",
      " 1.9104654669090033\n",
      " 1.9713965223819496\n",
      " 1.971395731497023\n",
      " 1.9713941787585625\n",
      " 0.8971043371498983\n",
      " 0.019160297196939177\n",
      " 0.019160296989536488\n",
      " 1.9713980272233411\n",
      " 1.971396388294141\n",
      " 0.022435220779828877\n",
      " 0.02243488671002538\n",
      " 1.9104750418658183\n",
      " 0.02243487944807963\n",
      " 1.9713985407064687\n",
      " 0.019160297040379106\n",
      " 0.02243499045743865\n",
      " 1.9713978430322157\n",
      " 1.9713961502785355\n",
      " 1.971393122241633\n",
      " 1.9713949811900615\n",
      " 1.9465443193529643\n",
      " 1.9713941253013192\n",
      " 1.9104722297195322\n",
      " 1.971398384590776\n",
      " 0.020773831722701464\n",
      " 0.02243501878315629\n",
      " 1.9713945720165418\n",
      " 0.5490303077849749\n",
      " 1.9713953650745373\n",
      " 0.019160296941764906\n",
      " 1.910444123599292\n",
      " 1.9713957919922902\n",
      " 1.9713979292713455\n",
      " 1.9713971610713434\n",
      " 0.022434864740287806\n",
      " 1.9713964919685878\n",
      " 0.8972054690815844\n",
      " 1.9713950766045882\n",
      " 0.022435172656783166\n",
      " 0.018105495119482683\n",
      " 0.01810549512607321\n",
      " 0.9731135657684296\n",
      " 0.9731135714591043\n",
      " 0.9731133510414786\n",
      " 0.9731130210125829\n",
      " 0.918669527668649\n",
      " 0.021162243436947115\n",
      " 0.021162236748864315\n",
      " 0.9731131535990521\n",
      " 0.9731130846190111\n",
      " 0.9186682993044312\n",
      " 0.018105495148064452\n",
      " 0.973113120946489\n",
      " 0.9731132800404086\n",
      " 0.9731125906642579\n",
      " 0.9731129116039164\n",
      " 0.9186706987022663\n",
      " 0.01810549512830903\n",
      " 0.01810549513431547\n",
      " 0.9731125669554043\n",
      " 0.9186691835351437\n",
      " 0.9731131181480579\n",
      " 0.9731135926955635\n",
      " 0.9731136040560662\n",
      " 0.9731132091734667\n",
      " 0.021162269805331296\n",
      " 0.9186691398504964\n",
      " 0.018105495164397502\n",
      " 0.9186685782977686\n",
      " 0.9186709094329093\n",
      " 0.9731132744004961\n",
      " 0.021162298280515024\n",
      " 0.9731132345911795\n",
      " 0.018105495121635687\n",
      " 0.9731136981506802\n",
      " 0.9186704689228893\n",
      " 0.9731129565061165\n",
      " 0.973113096976943\n",
      " 0.9731133352130416\n",
      " 0.9186699470051438\n",
      " 0.018105495146187797\n",
      " 0.9731130144263952\n",
      " 0.9731129655706604\n",
      " 0.9731136064433934\n",
      " 0.9731124377499641\n",
      " 0.01810549513851374\n",
      " 0.9186669197145657\n",
      " 0.9731134410420308\n",
      " 0.9186691071059443\n",
      " 0.9731128743195808\n",
      " 0.9731128088990482\n",
      " 0.018105495184909278\n",
      " 0.9731131918832253\n",
      " 0.01810549511086589\n",
      " 0.01810549516956817\n",
      " 0.9186658360980635\n",
      " 0.01810549512586666\n",
      " 0.021162348085206565\n",
      " 0.9731123919490117\n",
      " 0.9731129473197773\n",
      " 0.9731134622139331\n",
      " 0.918670473871192\n",
      " 0.9731132032142267\n",
      " 0.9186675556202748\n",
      " 0.9731134514864289\n",
      " 0.9731130297653504\n",
      " 0.9731131867312901\n",
      " 0.9731128970126459\n",
      " 0.01810549514443631\n",
      " 0.9731129282337133\n",
      " 0.9731131140811513\n",
      " 0.9731136667491431\n",
      " 0.9731127610498299\n",
      " 0.018105495100346543\n",
      " 0.021162288815140526\n",
      " 0.9186703578141046\n",
      " 0.9186691561423451\n",
      " 0.021162273579227325\n",
      " 0.9186683001565302\n",
      " 0.9731132806604679\n",
      " 0.9731132521528525\n",
      " 0.9731135851314118\n",
      " 0.018105495127474374\n",
      " 0.02116228564885375\n",
      " 0.9731131121285118\n",
      " 0.9186697181953473\n",
      " 0.9731127072551373\n",
      " 0.021162337399262113\n",
      " 0.021162219231804467\n",
      " 0.9186703176958856\n",
      " 0.018105495128682036\n",
      " 0.02116225974697556\n",
      " 0.018105495120738238\n",
      " 0.9731129776554053\n",
      " 0.9731133779291392\n",
      " 0.9186701640229401\n",
      " 0.021162255799051875\n",
      " 0.9186653733956736\n",
      " 0.9186704806648021\n",
      " 0.9731134427410869\n",
      " 0.018105495131903442\n",
      " 0.018105495151682614\n",
      " 0.018105495120156634\n",
      " 0.9186670436232283\n",
      " 0.9731128701732061\n",
      " 0.9731127249197113\n",
      " 0.9731134662724192\n",
      " 0.9186704242940001\n",
      " 0.9186698549803047\n",
      " 0.9186691755893194\n",
      " 0.973112683524719\n",
      " 0.01810549514802372\n",
      " 0.01810549517831367\n",
      " 0.9186667838280734\n",
      " 0.973113312794265\n",
      " 0.021162223214797497\n",
      " 0.02116224855406026\n",
      " 0.9731130195589724\n",
      " 0.021162231818390394\n",
      " 0.018105495153509094\n",
      " 0.01810549512684092\n",
      " 0.9186685199404198\n",
      " 0.021162266495338124\n",
      " 0.018105495207830682\n",
      " 0.9731137182413258\n",
      " 0.9731132367859345\n",
      " 0.9731136848475819\n",
      " 0.018105495202988955\n",
      " 0.9731129612366461\n",
      " 0.9731122773115343\n",
      " 0.9731130725295088\n",
      " 0.9186675663534498\n",
      " 0.9731134483351447\n",
      " 0.9731129451514399\n",
      " 0.021162250335873406\n",
      " 0.018105495120687255\n",
      " 0.018105495116392062\n",
      " 0.01810549512620255\n",
      " 0.0211622402142994\n",
      " 0.9731129237014194\n",
      " 0.018105495144064846\n",
      " 0.9186689977418002\n",
      " 0.9731122128949541\n",
      " 0.02116228952577603\n",
      " 0.9731125419531921\n",
      " 0.9731128418885887\n",
      " 0.9731122586093425\n",
      " 0.9731124692645786\n",
      " 0.9731134562928035\n",
      " 0.9731131861780248\n",
      " 0.9186685589885576\n",
      " 0.01810549511888747\n",
      " 0.9731133552501648\n",
      " 0.021162253986643953\n",
      " 0.9731131776856545\n",
      " 0.9731135016809365\n",
      " 0.9731135604595259\n",
      " 0.9731135444984467\n",
      " 0.9186684410141441\n",
      " 0.01810549517121194\n",
      " 0.9186664715344325\n",
      " 0.918669474281892\n",
      " 0.021162313858951967\n",
      " 0.018105495136574955\n",
      " 0.9731134361820165\n",
      " 0.018105495130215796\n",
      " 0.9731130231321287\n",
      " 0.018105495146779404\n",
      " 0.01810549520041736\n",
      " 0.973113270525142\n",
      " 0.021162249312702202\n",
      " 0.9186646672845401\n",
      " 0.01810549511953423\n",
      " 0.01810549512930292\n",
      " 0.9731131290763424\n",
      " 0.9731131387379263\n",
      " 0.01810549513243626\n",
      " 0.9731129573119527\n",
      " 0.9731127868213921\n",
      " 0.02116228202396244\n",
      " 0.9731133664677605\n",
      " 0.021162225264415784\n",
      " 0.9731123133451982\n",
      " 0.9186686938219902\n",
      " 0.01810549512510145\n",
      " 0.9186698105228159\n",
      " 0.018105495139942297\n",
      " 0.9731126285481899\n",
      " 0.9731122401117546\n",
      " 0.9731133906735482\n",
      " 0.02116225691050211\n",
      " 0.018105495130986807\n",
      " 0.02116228745913072\n",
      " 0.018105495130257738\n",
      " 0.01810549517461725\n",
      " 0.018105495125440317\n",
      " 0.9731136233530773\n",
      " 0.018105495164084735\n",
      " 0.9731133003932473\n",
      " 0.9731130760695411\n",
      " 0.021162282777409412\n",
      " 0.9186644476053563\n",
      " 0.973113365845336\n",
      " 0.9186707448538743\n",
      " 0.9731129033736116\n",
      " 0.9731132953781461\n",
      " 0.018105495145008022\n",
      " 0.9731128615925236\n",
      " 0.9731130690539331\n",
      " 0.9186676331350779\n",
      " 0.9731130655136364\n",
      " 0.021162326770069472\n",
      " 0.018105495206526608\n",
      " 0.9186694576473784\n",
      " 0.91866804285702\n",
      " 0.9731127437250598\n",
      " 0.02116232368804207\n",
      " 0.018105495159901865\n",
      " 0.9731134295295671\n",
      " 0.9731122789109824\n",
      " 0.9731129325798888\n",
      " 0.9186673223106175\n",
      " 0.973112962293204\n",
      " 0.9731132933998211\n",
      " 0.9731137136366651\n",
      " 0.9731129691330563\n",
      " 0.9731124685680391\n",
      " 0.9731129891431366\n",
      " 0.9731129826266234\n",
      " 0.973113162674284\n",
      " 0.01810549524929141\n",
      " 0.01810549519327664\n",
      " 0.9731137186741622\n",
      " 0.021162255778161634\n",
      " 0.9731133965732238\n",
      " 0.9186645859380972\n",
      " 0.973113070764162\n",
      " 0.9186693471678348\n",
      " 0.973113271854211\n",
      " 0.01810549510592133\n",
      " 0.9186658309147352\n",
      " 0.9186657860100077\n",
      " 0.018105495131995216\n",
      " 0.9731131698040483\n",
      " 0.9186685469329411\n",
      " 0.973112500678883\n",
      " 0.918670835047102\n",
      " 0.9186681539535132\n",
      "Topic 1:\n",
      " 0.02954043173911127\n",
      " 3.976879620672743\n",
      " 0.09404859886217048\n",
      " 3.976879547129586\n",
      " 3.9802722100377923\n",
      " 0.9630155387933109\n",
      " 0.029231538864582726\n",
      " 2.977111830473513\n",
      " 2.980464501102703\n",
      " 0.0292204897836442\n",
      " 0.9004962511363475\n",
      " 2.980464501118922\n",
      " 0.02921404026441905\n",
      " 0.029230940291090954\n",
      " 0.09249703110338994\n",
      " 2.9771114995834482\n",
      " 0.09253057156691649\n",
      " 0.029224908826748337\n",
      " 0.09254564081254583\n",
      " 1.5162818134161378\n",
      " 1.9775645168626808\n",
      " 1.063626462460558\n",
      " 0.028604244448458424\n",
      " 1.5040418485353246\n",
      " 0.08952764943358359\n",
      " 0.08952585936019031\n",
      " 0.08953453309099667\n",
      " 0.02860347761805038\n",
      " 0.028604268502976853\n",
      " 0.02860582124143751\n",
      " 1.1028956628501017\n",
      " 1.9808397028030609\n",
      " 1.9808397030104634\n",
      " 0.028601972776658924\n",
      " 0.02860361170585893\n",
      " 1.9775647792201714\n",
      " 1.9775651132899748\n",
      " 0.08952495813418178\n",
      " 1.9775651205519205\n",
      " 0.028601459293531403\n",
      " 1.9808397029596208\n",
      " 1.9775650095425614\n",
      " 0.028602156967784436\n",
      " 0.02860384972146441\n",
      " 0.028606877758367105\n",
      " 0.028605018809938303\n",
      " 0.05345568064703558\n",
      " 0.02860587469868061\n",
      " 0.08952777028046767\n",
      " 0.02860161540922383\n",
      " 1.9792261682772985\n",
      " 1.9775649812168439\n",
      " 0.028605427983458036\n",
      " 1.450969692215025\n",
      " 0.028604634925462606\n",
      " 1.980839703058235\n",
      " 0.08955587640070807\n",
      " 0.028604208007709908\n",
      " 0.0286020707286543\n",
      " 0.02860283892865646\n",
      " 1.9775651352597121\n",
      " 0.02860350803141224\n",
      " 1.1027945309184155\n",
      " 0.02860492339541187\n",
      " 1.977564827343217\n",
      " 0.9818945048805173\n",
      " 0.9818945048739268\n",
      " 0.026886434231570493\n",
      " 0.026886428540895683\n",
      " 0.026886648958521452\n",
      " 0.02688697898741701\n",
      " 0.081330472331351\n",
      " 0.9788377565630528\n",
      " 0.9788377632511356\n",
      " 0.026886846400947885\n",
      " 0.026886915380988884\n",
      " 0.08133170069556887\n",
      " 0.9818945048519356\n",
      " 0.026886879053511066\n",
      " 0.02688671995959136\n",
      " 0.026887409335741977\n",
      " 0.026887088396083537\n",
      " 0.08132930129773369\n",
      " 0.981894504871691\n",
      " 0.9818945048656845\n",
      " 0.026887433044595704\n",
      " 0.08133081646485626\n",
      " 0.026886881851942147\n",
      " 0.026886407304436356\n",
      " 0.02688639594393378\n",
      " 0.026886790826533308\n",
      " 0.9788377301946688\n",
      " 0.08133086014950364\n",
      " 0.9818945048356025\n",
      " 0.08133142170223144\n",
      " 0.08132909056709062\n",
      " 0.026886725599503915\n",
      " 0.978837701719485\n",
      " 0.026886765408820533\n",
      " 0.9818945048783643\n",
      " 0.026886301849319845\n",
      " 0.08132953107711066\n",
      " 0.026887043493883527\n",
      " 0.026886903023056873\n",
      " 0.026886664786958444\n",
      " 0.08133005299485628\n",
      " 0.9818945048538121\n",
      " 0.026886985573604867\n",
      " 0.026887034429339655\n",
      " 0.026886393556606606\n",
      " 0.026887562250035874\n",
      " 0.9818945048614862\n",
      " 0.08133308028543437\n",
      " 0.026886558957969178\n",
      " 0.08133089289405568\n",
      " 0.026887125680419097\n",
      " 0.02688719110095186\n",
      " 0.9818945048150908\n",
      " 0.026886808116774578\n",
      " 0.9818945048891341\n",
      " 0.9818945048304318\n",
      " 0.0813341639019364\n",
      " 0.9818945048741334\n",
      " 0.9788376519147934\n",
      " 0.02688760805098839\n",
      " 0.026887052680222692\n",
      " 0.02688653778606693\n",
      " 0.08132952612880799\n",
      " 0.026886796785773374\n",
      " 0.08133244437972516\n",
      " 0.026886548513571005\n",
      " 0.026886970234649626\n",
      " 0.0268868132687099\n",
      " 0.026887102987354108\n",
      " 0.9818945048555637\n",
      " 0.026887071766286682\n",
      " 0.02688688591884875\n",
      " 0.026886333250856927\n",
      " 0.026887238950170086\n",
      " 0.9818945048996534\n",
      " 0.9788377111848595\n",
      " 0.08132964218589535\n",
      " 0.08133084385765493\n",
      " 0.9788377264207726\n",
      " 0.08133169984346966\n",
      " 0.02688671933953208\n",
      " 0.026886747847147528\n",
      " 0.026886414868588292\n",
      " 0.9818945048725257\n",
      " 0.9788377143511462\n",
      " 0.02688688787148819\n",
      " 0.08133028180465278\n",
      " 0.026887292744862665\n",
      " 0.9788376626007378\n",
      " 0.9788377807681956\n",
      " 0.08132968230411439\n",
      " 0.9818945048713179\n",
      " 0.9788377402530245\n",
      " 0.9818945048792618\n",
      " 0.026887022344594808\n",
      " 0.026886622070860847\n",
      " 0.08132983597705977\n",
      " 0.9788377442009482\n",
      " 0.08133462660432636\n",
      " 0.08132951933519793\n",
      " 0.026886557258913115\n",
      " 0.9818945048680966\n",
      " 0.9818945048483174\n",
      " 0.9818945048798434\n",
      " 0.0813329563767717\n",
      " 0.026887129826793834\n",
      " 0.02688727508028856\n",
      " 0.026886533727580805\n",
      " 0.08132957570599984\n",
      " 0.0813301450196953\n",
      " 0.08133082441068064\n",
      " 0.026887316475280938\n",
      " 0.9818945048519763\n",
      " 0.9818945048216864\n",
      " 0.08133321617192658\n",
      " 0.026886687205735012\n",
      " 0.9788377767852025\n",
      " 0.9788377514459399\n",
      " 0.026886980441027535\n",
      " 0.9788377681816096\n",
      " 0.9818945048464909\n",
      " 0.9818945048731591\n",
      " 0.08133148005958016\n",
      " 0.978837733504662\n",
      " 0.9818945047921693\n",
      " 0.026886281758674285\n",
      " 0.02688676321406538\n",
      " 0.026886315152418083\n",
      " 0.981894504797011\n",
      " 0.026887038763353847\n",
      " 0.02688772268846574\n",
      " 0.026886927470491203\n",
      " 0.08133243364655017\n",
      " 0.026886551664855336\n",
      " 0.02688705484856009\n",
      " 0.9788377496641266\n",
      " 0.9818945048793126\n",
      " 0.981894504883608\n",
      " 0.9818945048737974\n",
      " 0.9788377597857006\n",
      " 0.026887076298580597\n",
      " 0.9818945048559351\n",
      " 0.08133100225819967\n",
      " 0.02688778710504593\n",
      " 0.978837710474224\n",
      " 0.02688745804680793\n",
      " 0.026887158111411184\n",
      " 0.026887741390657572\n",
      " 0.026887530735421397\n",
      " 0.0268865437071965\n",
      " 0.02688681382197521\n",
      " 0.08133144101144242\n",
      " 0.9818945048811125\n",
      " 0.02688664474983516\n",
      " 0.9788377460133559\n",
      " 0.02688682231434553\n",
      " 0.026886498319063583\n",
      " 0.026886439540474028\n",
      " 0.02688645550155342\n",
      " 0.08133155898585588\n",
      " 0.981894504828788\n",
      " 0.08133352846556757\n",
      " 0.08133052571810787\n",
      " 0.978837686141048\n",
      " 0.9818945048634251\n",
      " 0.026886563817983468\n",
      " 0.9818945048697841\n",
      " 0.02688697686787134\n",
      " 0.9818945048532205\n",
      " 0.9818945047995826\n",
      " 0.02688672947485803\n",
      " 0.9788377506872977\n",
      " 0.08133533271545977\n",
      " 0.9818945048804658\n",
      " 0.9818945048706971\n",
      " 0.026886870923657623\n",
      " 0.026886861262073763\n",
      " 0.9818945048675637\n",
      " 0.02688704268804734\n",
      " 0.02688721317860794\n",
      " 0.9788377179760376\n",
      " 0.026886633532239513\n",
      " 0.9788377747355843\n",
      " 0.026887686654801898\n",
      " 0.08133130617800978\n",
      " 0.9818945048748985\n",
      " 0.08133018947718412\n",
      " 0.9818945048600577\n",
      " 0.026887371451810173\n",
      " 0.026887759888245523\n",
      " 0.026886609326451847\n",
      " 0.978837743089498\n",
      " 0.9818945048690133\n",
      " 0.9788377125408693\n",
      " 0.9818945048697423\n",
      " 0.9818945048253827\n",
      " 0.9818945048745598\n",
      " 0.026886376646922797\n",
      " 0.9818945048359152\n",
      " 0.026886699606752735\n",
      " 0.026886923930458877\n",
      " 0.9788377172225905\n",
      " 0.08133555239464375\n",
      " 0.026886634154664007\n",
      " 0.08132925514612566\n",
      " 0.026887096626388402\n",
      " 0.02688670462185399\n",
      " 0.981894504854992\n",
      " 0.026887138407476398\n",
      " 0.026886930946066825\n",
      " 0.08133236686492198\n",
      " 0.02688693448636359\n",
      " 0.9788376732299305\n",
      " 0.9818945047934733\n",
      " 0.08133054235262163\n",
      " 0.08133195714298001\n",
      " 0.026887256274940072\n",
      " 0.9788376763119578\n",
      " 0.9818945048400981\n",
      " 0.026886570470432875\n",
      " 0.02688772108901757\n",
      " 0.026887067420111113\n",
      " 0.08133267768938239\n",
      " 0.02688703770679601\n",
      " 0.02688670660017884\n",
      " 0.026886286363334788\n",
      " 0.026887030866943634\n",
      " 0.02688753143196087\n",
      " 0.026887010856863423\n",
      " 0.026887017373376513\n",
      " 0.02688683732571592\n",
      " 0.9818945047507086\n",
      " 0.9818945048067234\n",
      " 0.026886281325837754\n",
      " 0.9788377442218384\n",
      " 0.02688660342677626\n",
      " 0.08133541406190277\n",
      " 0.026886929235837943\n",
      " 0.08133065283216533\n",
      " 0.02688672814578894\n",
      " 0.9818945048940787\n",
      " 0.08133416908526479\n",
      " 0.08133421398999224\n",
      " 0.9818945048680048\n",
      " 0.026886830195951745\n",
      " 0.08133145306705894\n",
      " 0.026887499321117045\n",
      " 0.08132916495289802\n",
      " 0.08133184604648672\n"
     ]
    }
   ],
   "source": [
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distribu;tions over vocab of \" + str(ldaModel.vocabSize())\n",
    "      + \" words):\")\n",
    "topics = ldaModel.topicsMatrix()\n",
    "for topic in range(2):\n",
    "    print(\"Topic \" + str(topic) + \":\")\n",
    "    for word in range(0, ldaModel.vocabSize()):\n",
    "        print(\" \" + str(topics[word][topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14637197,\n",
       "  DenseVector([0.0, 0.0, 0.0, 0.0, 4.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0])],\n",
       " [14637202,\n",
       "  DenseVector([0.0, 4.0, 0.0, 4.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])],\n",
       " [14637201,\n",
       "  DenseVector([0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0])],\n",
       " [14637200,\n",
       "  DenseVector([4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 3.0, 2.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0])]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parseData.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsevector = df_vect.select('vectors', 'text', 'textID').map(parseVectors)\n",
    "\n",
    "#Train the LDA model\n",
    "model = LDA.train(sparsevector, k=5, seed=1)\n",
    "\n",
    "#Print the topics in the model\n",
    "topics = model.describeTopics(maxTermsPerTopic = 15)\n",
    "for x, topic in enumerate(topics):\n",
    "    print ('topic nr: ' + str(x))\n",
    "    words = topic[0]\n",
    "    weights = topic[1]\n",
    "    for n in range(len(words)):\n",
    "        print (cvmodel.vocabulary[words[n]] + ' ' + str(weights[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('topic_result.txt', 'w') as f:\n",
    "    #Print the topics in the model\n",
    "    topics = ldaModel.describeTopics(maxTermsPerTopic = 10)\n",
    "    for x, topic in enumerate(topics):\n",
    "        f.write('topic nr: ' + str(x)+ '\\n')\n",
    "        words = topic[0]\n",
    "        weights = topic[1]\n",
    "        for n in range(len(words)):\n",
    "            f.write(cvmodel.vocabulary[words[n]] + ' ' + str(weights[n])+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
