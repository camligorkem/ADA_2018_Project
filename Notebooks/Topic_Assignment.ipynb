{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ke.csv', 'gh.csv', 'in.csv', 'gb.csv', 'bd.csv', 'us.csv', 'jm.csv', 'tz.csv', 'ng.csv', 'hk.csv', 'pk.csv', 'au.csv', 'lk.csv', 'ca.csv', 'za.csv', 'sg.csv', 'ph.csv', 'ie.csv', 'my.csv', 'nz.csv']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "C_PATH = '../Data/country/'\n",
    "countries = os.listdir(C_PATH)\n",
    "print(countries)\n",
    "\n",
    "COUNTRY_LIST = []\n",
    "for c in countries:\n",
    "    c_code = c[:2]\n",
    "    COUNTRY_LIST.append(c_code)\n",
    "print(len(COUNTRY_LIST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic assignments to LDA results\n",
    "\n",
    "LDA model produced and assigned each documents to one of its class. Since after exhaustive searches and trials we decided up using 7 class and pruning percentage of 95.5 each documents are assigned a topic value from 0 u to 6.\n",
    "\n",
    "Topic list is designed by us based on preliminary results (check all-pre-results folder). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ENVIRONMENT/ENERGY\n",
      "1 INTERNATIONAL\n",
      "2 POLITICS\n",
      "3 EDUCATION/FAMILY\n",
      "4 SPORTS\n",
      "5 TECHNOLOGY/SCIENCE/SOCIAL MEDIA\n",
      "6 SOCIAL_LIFE/DAILY\n",
      "7 ENTERTAINMENT/ART/MAGAZINE\n",
      "8 COMPANY/BUSINESS\n",
      "9 ECONOMY\n",
      "10 POLICE/ACCIDENT/VIOLENCE\n",
      "11 LEGAL/LAW\n",
      "12 HEALTH/MEDICAL\n"
     ]
    }
   ],
   "source": [
    "TOPIC_LIST = ['ENVIRONMENT/ENERGY','INTERNATIONAL','POLITICS','EDUCATION/FAMILY', \\\n",
    "              'SPORTS', 'TECHNOLOGY/SCIENCE/SOCIAL MEDIA', 'SOCIAL_LIFE/DAILY', \\\n",
    "              'ENTERTAINMENT/ART/MAGAZINE', 'COMPANY/BUSINESS', 'ECONOMY', \\\n",
    "              'POLICE/ACCIDENT/VIOLENCE', 'LEGAL/LAW','HEALTH/MEDICAL']\n",
    "for ind, val in enumerate(TOPIC_LIST):\n",
    "    print(ind, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary is designed according to LDA-class -> Topic list match.\n",
    "Structure is as following;\n",
    "\n",
    "country_code : {topic_assigned_by_LDA: {topic_id_from_Topiclist: percentage} }\n",
    "\n",
    "Here percentage enables us to assign multiple topic classes to a cluster discovered by LDA. For example LDA may discover topic_0 and news belonging to both POLITICS and INTERNATIONAL. With percentage approach, we are able to say 40\\% of topic_0 accounts for POLITICS whereas 60\\% accounts for INTERNATIONAL.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #country_code : {topic_assigned_by_LDA: {topic_id_from_Topiclist: percentage} }\n",
    "COUNTRY_DICT = {}\n",
    "\n",
    "COUNTRY_DICT['tz'] = {0:{6:90,12:10}, 1:{0:100}, 2:{1:50,2:50}, 3:{4:100}, 4:{5:100}, 5:{11:100}, 6:{8:50,12:50}} \n",
    "COUNTRY_DICT['bd'] = {0:{10:100}, 1:{1:50, 2:50}, 2:{1:100}, 3:{0:100}, 4:{6:100}, 5:{5:100}, 6:{11:100}}\n",
    "COUNTRY_DICT['gh'] = {0:{0:50,12:50}, 1:{1:40,4:60}, 2:{8:50, 9:50}, 3:{4:30,7:70}, 4:{11:100}, 5:{2:100}, 6:{7:100}} \n",
    "COUNTRY_DICT['hk'] = {0:{5:30,8:70}, 1:{2:100}, 2:{6:100}, 3:{1:100}, 4:{8:50,9:50}, 5:{10:100}, 6:{7:100}}\n",
    "\n",
    "COUNTRY_DICT['sg'] = {0:{7:100}, 1:{6:100}, 2:{10:100}, 3:{5:20,6:60,9:20}, 4:{8:100}, 5:{0:20,6:50,12:30}, 6:{5:100}} \n",
    "COUNTRY_DICT['pk'] = {0:{6:100}, 1:{2:100}, 2:{1:50,2:50}, 3:{1:100}, 4:{9:100}, 5:{2:50,1:50}, 6:{4:50,5:20,7:30}} \n",
    "COUNTRY_DICT['lk'] = {0:{0:100}, 1:{8:100}, 2:{2:40,10:60}, 3:{1:100}, 4:{5:100}, 5:{4:100}, 6:{6:100}} \n",
    "COUNTRY_DICT['my'] = {0:{5:100}, 1:{11:100}, 2:{2:90,10:10}, 3:{9:100}, 4:{0:100}, 5:{6:100}, 6:{5:60,8:40}} \n",
    "\n",
    "COUNTRY_DICT['nz'] = {0:{7:100}, 1:{8:10,11:90}, 2:{0:100}, 3:{4:100}, 4:{10:20,11:80}, 5:{12:100}, 6:{6:100}} \n",
    "COUNTRY_DICT['au'] = {0:{7:100}, 1:{4:100}, 2:{1:20,11:80}, 3:{12:100}, 4:{6:100}, 5:{9:100}, 6:{5:100}} \n",
    "COUNTRY_DICT['ca'] = {0:{12:100}, 1:{6:50,7:50}, 2:{10:100}, 3:{6:50,8:50}, 4:{0:100}, 5:{9:100}, 6:{0:30,4:70}} \n",
    "COUNTRY_DICT['gb'] = {0:{1:20,12:80}, 1:{4:50,6:50}, 2:{1:100}, 3:{7:10,11:90}, 4:{4:100}, 5:{7:100}, 6:{8:80,9:20}} \n",
    "\n",
    "COUNTRY_DICT['ng'] = {0:{4:100}, 1:{0:100}, 2:{1:50,2:50}, 3:{10:80,11:20}, 4:{7:100}, 5:{6:70,7:30}, 6:{9:100}} \n",
    "COUNTRY_DICT['za'] = {0:{1:50,2:50}, 1:{0:10,6:90}, 2:{1:50,12:50}, 3:{2:10,11:90}, 4:{5:50,12:50}, 5:{4:100}, 6:{9:100}} \n",
    "\n",
    "COUNTRY_DICT['ie'] = {0:{4:100}, 1:{11:100}, 2:{9:100}, 3:{6:50,12:50}, 4:{2:40,4:60}, 5:{2:100}, 6:{7:100}}\n",
    "COUNTRY_DICT['in'] = {0:{2:100}, 1:{8:80,11:20}, 2:{9:100}, 3:{7:100}, 4:{1:20,4:80}, 5:{5:100}, 6:{2:100}}\n",
    "COUNTRY_DICT['jm'] = {0:{0:20,12:80}, 1:{2:30,10:70}, 2:{8:60,12:40}, 3:{10:50,11:50}, 4:{6:100}, 5:{4:100}, 6:{7:100}} \n",
    "COUNTRY_DICT['ke'] = {0:{8:100}, 1:{8:50,9:50}, 2:{1:50,4:50}, 3:{6:100}, 4:{4:10,5:70,6:10,10:10}, 5:{6:20, 7:80}, 6:{10:50,11:50}}\n",
    "\n",
    "COUNTRY_DICT['ph'] = {0:{2:100}, 1:{12:50}, 2:{0:100}, 3:{10:100}, 4:{9:100}, 5:{4:100}, 6:{6:100}}\n",
    "COUNTRY_DICT['us'] = {0:{2:100}, 1:{2:40,10:60}, 2:{0:20,12:80}, 3:{6:70,11:30}, 4:{4:100}, 5:{8:50,9:50}, 6:{5:60,7:40}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read source data and asignment data merge\n",
    "\n",
    "To be able to get time, url etc features of articles we had to merge source information database already provided with article-topic dataframe we created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles we have \\(6 years\\)) is  6132175\n"
     ]
    }
   ],
   "source": [
    "# Read news source folder as a whole\n",
    "source_data = pd.read_table('../Data/now_sources_full.txt',encoding = \"ISO-8859-1\", header=None)\n",
    "source_data.rename(columns={0:'textID', 1:'#words',2:'date',3:'country',4:'website',5:'url',6:'title'},inplace=True)\n",
    "print('Total number of articles we have \\(6 years\\)) is ',len(source_data))\n",
    "source_data.dropna(inplace=True)\n",
    "source_data.date =  '20'+source_data.date\n",
    "source_data.date =  pd.to_datetime(source_data.date, format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide docs belong to a cluster of LDA into multiple topic according to percentage\n",
    "# NOTE: when we apply percentage distribution we did not sample the data, rather re-assigned topics in order\n",
    "\n",
    "def assign_percentage_topics(topic_frame, topic_dist):\n",
    "    \"\"\"\n",
    "    topic_frame: dataframe consists of doc_id and cluster_id(same for each)\n",
    "    topic_dist: dictionary consists of topic-matches as we decided\n",
    "    return: doc_id, topic_name dataframe\n",
    "    \"\"\"\n",
    "    slices = []\n",
    "    row_start = 0\n",
    "    row_end = 0\n",
    "    percen = 0\n",
    "    for t_id, t_dis in topic_dist.items():\n",
    "        \n",
    "        percen = (percen+t_dis)/100\n",
    "        row_end = row_start+  int(len(topic_frame)*percen)\n",
    "        mini_slice = topic_frame[row_start:row_end]\n",
    "        mini_slice.Topics = TOPIC_LIST[t_id]\n",
    "        \n",
    "        row_start = row_end\n",
    "        slices.append(mini_slice)\n",
    "    \n",
    "    return pd.concat(slices) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_by_country(c_code, c_dict):\n",
    "    \"\"\"\n",
    "    c_code: two character country code\n",
    "    c_dict: topic ssignments for that country\n",
    "    \"\"\"\n",
    "    assignment_data = pd.read_csv(C_PATH+ c_code +'.csv', header=None)\n",
    "    assignment_data.rename(columns={0:'textID', 1:'Topics'},inplace=True)\n",
    "    topic_frames = []\n",
    "    xx = []\n",
    "    for assign_topic in c_dict.keys():\n",
    "        t_fr = assign_percentage_topics(assignment_data[assignment_data.Topics==assign_topic],\\\n",
    "                                        c_dict[assign_topic])\n",
    "        topic_frames.append(t_fr)\n",
    "    return pd.concat(topic_frames),xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_frames = []\n",
    "for cind in range(len(COUNTRY_LIST)) :\n",
    "    c_code = COUNTRY_LIST[cind]\n",
    "    c_dict = COUNTRY_DICT[c_code]\n",
    "    per_country,xx = get_article_by_country(c_code, c_dict)\n",
    "    c_frames.append(per_country)\n",
    "\n",
    "all_counries = pd.concat(c_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>#words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>website</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3732490</td>\n",
       "      <td>815</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>NPR</td>\n",
       "      <td>http://www.npr.org/2015/11/01/450889721/the-ma...</td>\n",
       "      <td>The Madonna Of 115th Street Gets A Long-Awaite...</td>\n",
       "      <td>SOCIAL_LIFE/DAILY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3732492</td>\n",
       "      <td>258</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>http://www.huffingtonpost.com/entry/university...</td>\n",
       "      <td>University Of Louisville Sorry A Bunch Of Its ...</td>\n",
       "      <td>SOCIAL_LIFE/DAILY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3732496</td>\n",
       "      <td>489</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Bleacher Report</td>\n",
       "      <td>http://bleacherreport.com/articles/2584708-kar...</td>\n",
       "      <td>'Kareem: Minority of One' HBO Documentary Prev...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3732501</td>\n",
       "      <td>840</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>VentureBeat</td>\n",
       "      <td>http://venturebeat.com/2015/11/01/what-big-ind...</td>\n",
       "      <td>What big industry will do to the Internet of T...</td>\n",
       "      <td>HEALTH/MEDICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3732502</td>\n",
       "      <td>470</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Tech Insider</td>\n",
       "      <td>http://www.techinsider.io/daenerys-game-of-thr...</td>\n",
       "      <td>Daenerys has been traveling in the wrong direc...</td>\n",
       "      <td>SPORTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    textID  #words       date country          website  \\\n",
       "0  3732490     815 2015-11-01      US              NPR   \n",
       "1  3732492     258 2015-11-01      US  Huffington Post   \n",
       "2  3732496     489 2015-11-01      US  Bleacher Report   \n",
       "3  3732501     840 2015-11-01      US      VentureBeat   \n",
       "4  3732502     470 2015-11-01      US    Tech Insider    \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.npr.org/2015/11/01/450889721/the-ma...   \n",
       "1  http://www.huffingtonpost.com/entry/university...   \n",
       "2  http://bleacherreport.com/articles/2584708-kar...   \n",
       "3  http://venturebeat.com/2015/11/01/what-big-ind...   \n",
       "4  http://www.techinsider.io/daenerys-game-of-thr...   \n",
       "\n",
       "                                               title             Topics  \n",
       "0  The Madonna Of 115th Street Gets A Long-Awaite...  SOCIAL_LIFE/DAILY  \n",
       "1  University Of Louisville Sorry A Bunch Of Its ...  SOCIAL_LIFE/DAILY  \n",
       "2  'Kareem: Minority of One' HBO Documentary Prev...           POLITICS  \n",
       "3  What big industry will do to the Internet of T...     HEALTH/MEDICAL  \n",
       "4  Daenerys has been traveling in the wrong direc...             SPORTS  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All necessary infomations to run correlations\n",
    "full_data = pd.merge(source_data, all_counries, left_on='textID', right_on='textID')\n",
    "# News_Id, Topic of the News and all others...\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of news have a specific topic per country\n",
    "g_country_topic = full_data.groupby(by=['country','Topics'])['textID'].count()\n",
    "g_country = g_country_topic.groupby(by=['country']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country  Topics                         \n",
       "AU       ECONOMY                            0.157716\n",
       "         ENTERTAINMENT/ART/MAGAZINE         0.153065\n",
       "         HEALTH/MEDICAL                     0.141965\n",
       "         INTERNATIONAL                      0.029435\n",
       "         LEGAL/LAW                          0.117698\n",
       "         SOCIAL_LIFE/DAILY                  0.112324\n",
       "         SPORTS                             0.124271\n",
       "         TECHNOLOGY/SCIENCE/SOCIAL MEDIA    0.163525\n",
       "BD       ENVIRONMENT/ENERGY                 0.157019\n",
       "         INTERNATIONAL                      0.175870\n",
       "         LEGAL/LAW                          0.212020\n",
       "         POLICE/ACCIDENT/VIOLENCE           0.175870\n",
       "         POLITICS                           0.034819\n",
       "         SOCIAL_LIFE/DAILY                  0.133289\n",
       "         TECHNOLOGY/SCIENCE/SOCIAL MEDIA    0.111111\n",
       "CA       COMPANY/BUSINESS                   0.073039\n",
       "         ECONOMY                            0.138273\n",
       "         ENTERTAINMENT/ART/MAGAZINE         0.073039\n",
       "         ENVIRONMENT/ENERGY                 0.194973\n",
       "         HEALTH/MEDICAL                     0.113016\n",
       "         POLICE/ACCIDENT/VIOLENCE           0.165221\n",
       "         SOCIAL_LIFE/DAILY                  0.146600\n",
       "         SPORTS                             0.095840\n",
       "GB       COMPANY/BUSINESS                   0.148592\n",
       "         ECONOMY                            0.037203\n",
       "         ENTERTAINMENT/ART/MAGAZINE         0.147708\n",
       "         HEALTH/MEDICAL                     0.083868\n",
       "         INTERNATIONAL                      0.175466\n",
       "         LEGAL/LAW                          0.121004\n",
       "         SOCIAL_LIFE/DAILY                  0.057249\n",
       "                                              ...   \n",
       "SG       TECHNOLOGY/SCIENCE/SOCIAL MEDIA    0.178334\n",
       "TZ       COMPANY/BUSINESS                   0.051928\n",
       "         ENVIRONMENT/ENERGY                 0.107789\n",
       "         HEALTH/MEDICAL                     0.061369\n",
       "         INTERNATIONAL                      0.066090\n",
       "         LEGAL/LAW                          0.141621\n",
       "         POLITICS                           0.069237\n",
       "         SOCIAL_LIFE/DAILY                  0.117231\n",
       "         SPORTS                             0.092840\n",
       "         TECHNOLOGY/SCIENCE/SOCIAL MEDIA    0.291896\n",
       "US       COMPANY/BUSINESS                   0.084825\n",
       "         ECONOMY                            0.084809\n",
       "         ENTERTAINMENT/ART/MAGAZINE         0.055243\n",
       "         ENVIRONMENT/ENERGY                 0.022056\n",
       "         HEALTH/MEDICAL                     0.088082\n",
       "         LEGAL/LAW                          0.056618\n",
       "         POLICE/ACCIDENT/VIOLENCE           0.084572\n",
       "         POLITICS                           0.194978\n",
       "         SOCIAL_LIFE/DAILY                  0.132510\n",
       "         SPORTS                             0.113442\n",
       "         TECHNOLOGY/SCIENCE/SOCIAL MEDIA    0.082864\n",
       "ZA       ECONOMY                            0.141502\n",
       "         ENVIRONMENT/ENERGY                 0.014033\n",
       "         HEALTH/MEDICAL                     0.126764\n",
       "         INTERNATIONAL                      0.148688\n",
       "         LEGAL/LAW                          0.099430\n",
       "         POLITICS                           0.090337\n",
       "         SOCIAL_LIFE/DAILY                  0.125849\n",
       "         SPORTS                             0.196457\n",
       "         TECHNOLOGY/SCIENCE/SOCIAL MEDIA    0.056941\n",
       "Name: textID, Length: 165, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentages of topics\n",
    "g_percentage = g_country_topic/g_country\n",
    "g_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cells, we created a matrix shows for each country, percentage of the topic (non values if not match in that country for that topic). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_distribution = pd.DataFrame(full_data['country'].unique()) \n",
    "topics_distribution.rename(columns={0:'country'},inplace=True)\n",
    "topics_distribution['country_name'] = ['United States', \n",
    "                                       'Canada', \n",
    "                                       'United Kingdom',\n",
    "                                       'Ireland',\n",
    "                                        'Australia',\n",
    "                                        'New Zealand',\n",
    "                                        'India',\n",
    "                                        'Sri Lanka',\n",
    "                                       'Pakistan', \n",
    "                                       'Bangladesh',\n",
    "                                        'Malaysia',\n",
    "                                        'Singapore',\n",
    "                                        'Philippines',\n",
    "                                       'Hong Kong',\n",
    "                                       'South Africa',\n",
    "                                        'Nigeria', \n",
    "                                        'Ghana',\n",
    "                                        'Kenya',                           \n",
    "                                        'Tanzania',\n",
    "                                       'Jamaica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a none matrix ready\n",
    "for col in TOPIC_LIST:\n",
    "    topics_distribution[col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>Topics</th>\n",
       "      <th>textID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AU</td>\n",
       "      <td>ECONOMY</td>\n",
       "      <td>0.157716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AU</td>\n",
       "      <td>ENTERTAINMENT/ART/MAGAZINE</td>\n",
       "      <td>0.153065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AU</td>\n",
       "      <td>HEALTH/MEDICAL</td>\n",
       "      <td>0.141965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AU</td>\n",
       "      <td>INTERNATIONAL</td>\n",
       "      <td>0.029435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AU</td>\n",
       "      <td>LEGAL/LAW</td>\n",
       "      <td>0.117698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                      Topics    textID\n",
       "0      AU                     ECONOMY  0.157716\n",
       "1      AU  ENTERTAINMENT/ART/MAGAZINE  0.153065\n",
       "2      AU              HEALTH/MEDICAL  0.141965\n",
       "3      AU               INTERNATIONAL  0.029435\n",
       "4      AU                   LEGAL/LAW  0.117698"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_percentage_pd = pd.DataFrame(g_percentage)\n",
    "g_percentage_pd.reset_index(inplace=True)\n",
    "g_percentage_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the matrix\n",
    "for ind, row in g_percentage_pd.iterrows():\n",
    "    country = row.country\n",
    "    topic = row.Topics\n",
    "    freq = row.textID\n",
    "    topics_distribution.loc[topics_distribution['country'] == country, topic] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>country_name</th>\n",
       "      <th>ENVIRONMENT/ENERGY</th>\n",
       "      <th>INTERNATIONAL</th>\n",
       "      <th>POLITICS</th>\n",
       "      <th>EDUCATION/FAMILY</th>\n",
       "      <th>SPORTS</th>\n",
       "      <th>TECHNOLOGY/SCIENCE/SOCIAL MEDIA</th>\n",
       "      <th>SOCIAL_LIFE/DAILY</th>\n",
       "      <th>ENTERTAINMENT/ART/MAGAZINE</th>\n",
       "      <th>COMPANY/BUSINESS</th>\n",
       "      <th>ECONOMY</th>\n",
       "      <th>POLICE/ACCIDENT/VIOLENCE</th>\n",
       "      <th>LEGAL/LAW</th>\n",
       "      <th>HEALTH/MEDICAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>0.022056</td>\n",
       "      <td>None</td>\n",
       "      <td>0.194978</td>\n",
       "      <td>None</td>\n",
       "      <td>0.113442</td>\n",
       "      <td>0.0828643</td>\n",
       "      <td>0.13251</td>\n",
       "      <td>0.0552429</td>\n",
       "      <td>0.0848248</td>\n",
       "      <td>0.084809</td>\n",
       "      <td>0.0845718</td>\n",
       "      <td>0.0566184</td>\n",
       "      <td>0.0880818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.194973</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0958403</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.0730386</td>\n",
       "      <td>0.0730386</td>\n",
       "      <td>0.138273</td>\n",
       "      <td>0.165221</td>\n",
       "      <td>None</td>\n",
       "      <td>0.113016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GB</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>None</td>\n",
       "      <td>0.175466</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.22891</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0572487</td>\n",
       "      <td>0.147708</td>\n",
       "      <td>0.148592</td>\n",
       "      <td>0.0372031</td>\n",
       "      <td>None</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.0838684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IE</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.177962</td>\n",
       "      <td>None</td>\n",
       "      <td>0.252041</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0542922</td>\n",
       "      <td>0.184377</td>\n",
       "      <td>None</td>\n",
       "      <td>0.143317</td>\n",
       "      <td>None</td>\n",
       "      <td>0.13386</td>\n",
       "      <td>0.0541523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AU</td>\n",
       "      <td>Australia</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0294349</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>0.163525</td>\n",
       "      <td>0.112324</td>\n",
       "      <td>0.153065</td>\n",
       "      <td>None</td>\n",
       "      <td>0.157716</td>\n",
       "      <td>None</td>\n",
       "      <td>0.117698</td>\n",
       "      <td>0.141965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country    country_name ENVIRONMENT/ENERGY INTERNATIONAL  POLITICS  \\\n",
       "0      US   United States           0.022056          None  0.194978   \n",
       "1      CA          Canada           0.194973          None      None   \n",
       "2      GB  United Kingdom               None      0.175466      None   \n",
       "3      IE         Ireland               None          None  0.177962   \n",
       "4      AU       Australia               None     0.0294349      None   \n",
       "\n",
       "  EDUCATION/FAMILY     SPORTS TECHNOLOGY/SCIENCE/SOCIAL MEDIA  \\\n",
       "0             None   0.113442                       0.0828643   \n",
       "1             None  0.0958403                            None   \n",
       "2             None    0.22891                            None   \n",
       "3             None   0.252041                            None   \n",
       "4             None   0.124271                        0.163525   \n",
       "\n",
       "  SOCIAL_LIFE/DAILY ENTERTAINMENT/ART/MAGAZINE COMPANY/BUSINESS    ECONOMY  \\\n",
       "0           0.13251                  0.0552429        0.0848248   0.084809   \n",
       "1            0.1466                  0.0730386        0.0730386   0.138273   \n",
       "2         0.0572487                   0.147708         0.148592  0.0372031   \n",
       "3         0.0542922                   0.184377             None   0.143317   \n",
       "4          0.112324                   0.153065             None   0.157716   \n",
       "\n",
       "  POLICE/ACCIDENT/VIOLENCE  LEGAL/LAW HEALTH/MEDICAL  \n",
       "0                0.0845718  0.0566184      0.0880818  \n",
       "1                 0.165221       None       0.113016  \n",
       "2                     None   0.121004      0.0838684  \n",
       "3                     None    0.13386      0.0541523  \n",
       "4                     None   0.117698       0.141965  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic distribution matrix\n",
    "topics_distribution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "topics_distribution.to_csv('../Data/topic_distribution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "full_data.to_csv('../Data/final-news-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent words appeared in dominant topics for each country\n",
    "\n",
    "After calculations and visualizations (plots notebook), dominant topic for each country per year is know. This are 5 most frequent words (out of 10) found by LDA regarding the dominant topic. These words are extracted manual examinations of LDA results for each country. One can reach full list of words per topic per country under LDAResults directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dominant topics is chosen as the one which biggest particion of docs are assigned\n",
    "words_c = { 'us':['electoral','romney','objectionable','pentagon','libertarian','POLITICS'],\n",
    "         'ie':['klopp','sunderland','spur','coleman','horgan','SPORTS'],\n",
    "         'ca':['fossil','tracking','hectare','brook','panther','ENVIRONMENT/ENERGY'],\n",
    "         'gb':['wimbledon','milan','diego','clark','spearhead','SPORTS'],\n",
    "         'gh':['entertainment','wear','actress','gospel','george','ENTERTAINMENT/ART/MAGAZINE'],\n",
    "         'bd':['lawyer','sentence','supreme','petition','allegation','LEGAL/LAW'],\n",
    "         'hk':['insurance','marketing','partneship','secure','monetary','COMPANY/BUSINESS'],\n",
    "         'ng':['stock','trillion','regulatory','manufacturing','trader','ECONOMY'],\n",
    "         'pk':['congress','erdogan','coup','china-pakistan','census','POLITICS'],\n",
    "         'sg':['merger','deutsche','malay','civillian','religion','SOCIAL_LIFE/DAILY'],\n",
    "         'tz':['operator','online','user','stream','provider','TECHNOLOGY/SCIENCE/SOCIAL MEDIA'],\n",
    "         'za':['teammate','fitness','warrior','celtic','winning','SPORTS'],\n",
    "         'in':['puja','shaka','azad','anti-nation','liberal','POLITICS'],\n",
    "         'jm':['video','perform','dance','popular','singer','ENTERTAINMENT/ART/MAGAZINE'],\n",
    "         'ke':['innovation','consumption','planning','profit','machinery','COMPANY/BUSINESS'],\n",
    "         'lk':['disaster','submit','flood','coal','allege','ENVIRONMENT/ENERGY'],\n",
    "         'my':['auto','circuit','researcher','tech','computer','TECHNOLOGY/SCIENCE/SOCIAL MEDIA'],\n",
    "         'nz':['copyright','prohibit','prosecutor','supreme','suspend','LEGAL/LAW'],\n",
    "         'ph':['firearm','supt','raid','calamity','isolated','POLICE/ACCIDENT/VIOLENCE'],\n",
    "         'au':['nasa','integrate','wireless','hybrid','audio','TECHNOLOGY/SCIENCE/SOCIAL MEDIA']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq =  pd.DataFrame.from_dict(words_c)\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq.to_csv('../Data/most_freq_words.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
