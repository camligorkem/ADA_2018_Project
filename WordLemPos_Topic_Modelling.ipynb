{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordLemPos Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/gorkem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "import csv\n",
    "\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Import stopwords with nltk.\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using WordLemPos data, we will try to find topics of the dataset. What we do as a first step is to check one month data for one country and see if we can find some meaningful results.\n",
    "We will check October 2016, US data for this purpose. If our results seems meaningful, we will try with one year data and expand gradually from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read wordLemPos Data file \n",
    "data_folder='sample_data/'\n",
    "fileName= '16-10-us.txt'\n",
    "wordLemPos_big = pd.read_table(data_folder+fileName, quoting=csv.QUOTE_NONE, encoding = \"ISO-8859-1\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordLemPos = wordLemPos_big.copy()\n",
    "numRows = len(wordLemPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17564427, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839025</td>\n",
       "      <td>@@14637197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839026</td>\n",
       "      <td>&lt;p&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839027</td>\n",
       "      <td>NEW</td>\n",
       "      <td>new</td>\n",
       "      <td>np1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839028</td>\n",
       "      <td>YORK</td>\n",
       "      <td>york</td>\n",
       "      <td>np1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839029</td>\n",
       "      <td>(</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839030</td>\n",
       "      <td>AP</td>\n",
       "      <td>ap</td>\n",
       "      <td>np1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839031</td>\n",
       "      <td>)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839032</td>\n",
       "      <td>--</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jj_nn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839033</td>\n",
       "      <td>Donald</td>\n",
       "      <td>donald</td>\n",
       "      <td>np1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839034</td>\n",
       "      <td>Trump</td>\n",
       "      <td>trump</td>\n",
       "      <td>nn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839035</td>\n",
       "      <td>'s</td>\n",
       "      <td>'s</td>\n",
       "      <td>ge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839036</td>\n",
       "      <td>five-day</td>\n",
       "      <td>five-day</td>\n",
       "      <td>jj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839037</td>\n",
       "      <td>feud</td>\n",
       "      <td>feud</td>\n",
       "      <td>nn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839038</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>iw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839039</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>at1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839040</td>\n",
       "      <td>former</td>\n",
       "      <td>former</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839041</td>\n",
       "      <td>beauty</td>\n",
       "      <td>beauty</td>\n",
       "      <td>nn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839042</td>\n",
       "      <td>queen</td>\n",
       "      <td>queen</td>\n",
       "      <td>nn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839043</td>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>vbz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14637197</td>\n",
       "      <td>4739839044</td>\n",
       "      <td>only</td>\n",
       "      <td>only</td>\n",
       "      <td>rr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1           2         3       4\n",
       "0   14637197  4739839025  @@14637197       NaN      fo\n",
       "1   14637197  4739839026         <p>       NaN     NaN\n",
       "2   14637197  4739839027         NEW       new     np1\n",
       "3   14637197  4739839028        YORK      york     np1\n",
       "4   14637197  4739839029           (       NaN       (\n",
       "5   14637197  4739839030          AP        ap     np1\n",
       "6   14637197  4739839031           )       NaN       )\n",
       "7   14637197  4739839032          --       NaN  jj_nn1\n",
       "8   14637197  4739839033      Donald    donald     np1\n",
       "9   14637197  4739839034       Trump     trump     nn1\n",
       "10  14637197  4739839035          's        's      ge\n",
       "11  14637197  4739839036    five-day  five-day      jj\n",
       "12  14637197  4739839037        feud      feud     nn1\n",
       "13  14637197  4739839038        with      with      iw\n",
       "14  14637197  4739839039           a         a     at1\n",
       "15  14637197  4739839040      former    former      da\n",
       "16  14637197  4739839041      beauty    beauty     nn1\n",
       "17  14637197  4739839042       queen     queen     nn1\n",
       "18  14637197  4739839043          is        be     vbz\n",
       "19  14637197  4739839044        only      only      rr"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape and content of the data\n",
    "display(wordLemPos.shape)\n",
    "wordLemPos.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is useful for this data is the lemma-stemmed version of the words of each position. By using them we will skip the preprocessing part of the words lemmatization and stemming. Therefore, we want textID and lemma columns from the data. Also we drop the ones that are NA in lemma since it means they are either special char or numbers and don't have a root word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14637197</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14637197</td>\n",
       "      <td>york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14637197</td>\n",
       "      <td>ap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14637197</td>\n",
       "      <td>donald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14637197</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14637197</td>\n",
       "      <td>'s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14637197</td>\n",
       "      <td>five-day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14637197</td>\n",
       "      <td>feud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14637197</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14637197</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      textID     lemma\n",
       "2   14637197       new\n",
       "3   14637197      york\n",
       "5   14637197        ap\n",
       "8   14637197    donald\n",
       "9   14637197     trump\n",
       "10  14637197        's\n",
       "11  14637197  five-day\n",
       "12  14637197      feud\n",
       "13  14637197      with\n",
       "14  14637197         a"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wordLemPos.rename(columns={0:'textID',1:'ID(seq)',2:'word',3:'lemma',4:'PoS'},inplace=True)\n",
    "wordLemPos = wordLemPos[['textID','lemma']]\n",
    "# Drop NA values we are not interested in null lemma's since \n",
    "# they are not words but special characters and numbers\n",
    "wordLemPos.dropna(inplace=True)\n",
    "wordLemPos.shape\n",
    "display(wordLemPos.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the WordLemPos data for each news article words are already preprocessed and lemmatized and stemmed. What we need to do first is to get rid off the stop words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordLemPos = wordLemPos[:numRows]\n",
    "#display(wordLemPos.shape)\n",
    "#display(wordLemPos.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove stopwords we have several conditions the word shouldn't be nltk or gensim.parsing stopword dictionary, it shouldn't be in unnecessary words and the length of the word should be bigger than 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some unnecessary words found common but not useful for the topic modelling, we excluded them\n",
    "unnecessary_words=['new','good','high','big','with','into','under',\n",
    "                  'really','already','still','early','while','although','most','every','which',\n",
    "                  'year','like','time','that','given','would']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6135938, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14637197</td>\n",
       "      <td>york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14637197</td>\n",
       "      <td>donald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14637197</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14637197</td>\n",
       "      <td>five-day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14637197</td>\n",
       "      <td>feud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14637197</td>\n",
       "      <td>beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14637197</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14637197</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14637197</td>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14637197</td>\n",
       "      <td>insistence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      textID       lemma\n",
       "3   14637197        york\n",
       "8   14637197      donald\n",
       "9   14637197       trump\n",
       "11  14637197    five-day\n",
       "12  14637197        feud\n",
       "16  14637197      beauty\n",
       "17  14637197       queen\n",
       "21  14637197        late\n",
       "22  14637197     example\n",
       "25  14637197  insistence"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find stop words, replace with nullin lemma\n",
    "wordLemPos['lemma'] = wordLemPos.lemma.apply((lambda x: x if x not in (stop) \n",
    "                                              and len(x)>3 \n",
    "                                              and x not in gensim.parsing.preprocessing.STOPWORDS\n",
    "                                              and x not in unnecessary_words\n",
    "                                              else None))\n",
    "# Drop lemma null - which are the stopwords\n",
    "wordLemPos.dropna(inplace=True)\n",
    "display(wordLemPos.shape)\n",
    "display(wordLemPos.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filtering the stopwords, we will make the words ready for the LDA.\n",
    "For each unique textID we group the words and turn them into list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of words for each article\n",
    "unique_textID = wordLemPos.textID.unique()\n",
    "docs =[]\n",
    "for text_id in unique_textID:\n",
    "    doc = wordLemPos[wordLemPos.textID==text_id]['lemma'].tolist()\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26028"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many article we have\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create bag of words. Assign a number key for each word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 30-day\n",
      "1 airing\n",
      "2 article\n",
      "3 beauty\n",
      "4 brag\n",
      "5 brash\n",
      "6 businessman\n",
      "7 campaign\n",
      "8 celebrity\n",
      "9 cheer\n",
      "10 combat\n"
     ]
    }
   ],
   "source": [
    "# bag of words on the dataset\n",
    "dictionary = gensim.corpora.Dictionary(docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another good approach is to filter the words there are not very common on the article to ease the further steps and computation. If word count is very few within the given documents then it is probably not related to find the topic of the article, so we can clear them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the tokens that are seen less than x documents\n",
    "docThreshold = 15\n",
    "dictionary.filter_extremes(no_below=docThreshold, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create doc2bow which is for each document we count the words they have and store them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create doc2bow\n",
    "# For each doc have a dictionary stating how many words and how many times each word appears\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "#bow_corpus[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually need also bow_doc results for our further analysis as well. Therefore, we will save it to use for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 11 (\"come\") appears 3 time.\n",
      "Word 15 (\"cost\") appears 2 time.\n",
      "Word 19 (\"example\") appears 1 time.\n",
      "Word 29 (\"local\") appears 1 time.\n",
      "Word 32 (\"need\") appears 1 time.\n",
      "Word 37 (\"people\") appears 1 time.\n",
      "Word 38 (\"period\") appears 1 time.\n",
      "Word 39 (\"political\") appears 1 time.\n",
      "Word 45 (\"service\") appears 3 time.\n",
      "Word 56 (\"unfairly\") appears 1 time.\n",
      "Word 68 (\"basically\") appears 1 time.\n",
      "Word 78 (\"change\") appears 1 time.\n",
      "Word 108 (\"gain\") appears 1 time.\n",
      "Word 115 (\"happen\") appears 1 time.\n",
      "Word 123 (\"instead\") appears 1 time.\n",
      "Word 146 (\"opportunity\") appears 1 time.\n",
      "Word 152 (\"play\") appears 1 time.\n",
      "Word 188 (\"work\") appears 2 time.\n",
      "Word 210 (\"heart\") appears 1 time.\n",
      "Word 223 (\"project\") appears 1 time.\n",
      "Word 230 (\"seat\") appears 1 time.\n",
      "Word 231 (\"seek\") appears 1 time.\n",
      "Word 242 (\"want\") appears 3 time.\n",
      "Word 259 (\"answer\") appears 1 time.\n",
      "Word 275 (\"board\") appears 11 time.\n",
      "Word 280 (\"business\") appears 1 time.\n",
      "Word 286 (\"certain\") appears 1 time.\n",
      "Word 295 (\"comment\") appears 2 time.\n",
      "Word 320 (\"director\") appears 1 time.\n",
      "Word 334 (\"exactly\") appears 1 time.\n",
      "Word 335 (\"expect\") appears 1 time.\n",
      "Word 358 (\"general\") appears 1 time.\n",
      "Word 377 (\"inform\") appears 1 time.\n",
      "Word 385 (\"large\") appears 2 time.\n",
      "Word 395 (\"long\") appears 1 time.\n",
      "Word 418 (\"near\") appears 1 time.\n",
      "Word 446 (\"population\") appears 1 time.\n",
      "Word 454 (\"problem\") appears 1 time.\n",
      "Word 457 (\"public\") appears 3 time.\n",
      "Word 466 (\"rate\") appears 3 time.\n",
      "Word 473 (\"recent\") appears 1 time.\n",
      "Word 491 (\"response\") appears 1 time.\n",
      "Word 510 (\"shut\") appears 1 time.\n",
      "Word 512 (\"significant\") appears 1 time.\n",
      "Word 526 (\"standard\") appears 1 time.\n",
      "Word 547 (\"thing\") appears 1 time.\n",
      "Word 548 (\"think\") appears 1 time.\n",
      "Word 565 (\"understand\") appears 1 time.\n",
      "Word 574 (\"water\") appears 3 time.\n",
      "Word 590 (\"boost\") appears 1 time.\n",
      "Word 595 (\"company\") appears 1 time.\n",
      "Word 611 (\"member\") appears 4 time.\n",
      "Word 674 (\"issue\") appears 2 time.\n",
      "Word 677 (\"know\") appears 2 time.\n",
      "Word 682 (\"management\") appears 1 time.\n",
      "Word 700 (\"safety\") appears 1 time.\n",
      "Word 707 (\"small\") appears 1 time.\n",
      "Word 736 (\"career\") appears 1 time.\n",
      "Word 745 (\"contender\") appears 1 time.\n",
      "Word 751 (\"decade\") appears 1 time.\n",
      "Word 770 (\"including\") appears 1 time.\n",
      "Word 853 (\"field\") appears 2 time.\n",
      "Word 942 (\"perspective\") appears 2 time.\n",
      "Word 947 (\"push\") appears 2 time.\n",
      "Word 972 (\"charge\") appears 3 time.\n",
      "Word 988 (\"retired\") appears 2 time.\n",
      "Word 993 (\"woman\") appears 1 time.\n",
      "Word 994 (\"11th\") appears 1 time.\n",
      "Word 995 (\"2000s\") appears 1 time.\n",
      "Word 996 (\"2018\") appears 1 time.\n",
      "Word 997 (\"30-year\") appears 1 time.\n",
      "Word 998 (\"advocate\") appears 1 time.\n",
      "Word 999 (\"agreement\") appears 2 time.\n",
      "Word 1000 (\"analyze\") appears 1 time.\n",
      "Word 1001 (\"apartment\") appears 1 time.\n",
      "Word 1002 (\"appointee\") appears 1 time.\n",
      "Word 1003 (\"asset\") appears 2 time.\n",
      "Word 1004 (\"avoid\") appears 1 time.\n",
      "Word 1005 (\"blaze\") appears 1 time.\n",
      "Word 1006 (\"boundary\") appears 1 time.\n",
      "Word 1007 (\"budget\") appears 1 time.\n",
      "Word 1008 (\"burden\") appears 1 time.\n",
      "Word 1009 (\"candidate\") appears 1 time.\n",
      "Word 1010 (\"card\") appears 1 time.\n",
      "Word 1011 (\"choice\") appears 1 time.\n",
      "Word 1012 (\"choose\") appears 1 time.\n",
      "Word 1013 (\"cite\") appears 1 time.\n",
      "Word 1014 (\"clean\") appears 1 time.\n",
      "Word 1015 (\"comfortable\") appears 2 time.\n",
      "Word 1016 (\"consumption\") appears 1 time.\n",
      "Word 1017 (\"contribution\") appears 1 time.\n",
      "Word 1018 (\"counsel\") appears 1 time.\n",
      "Word 1019 (\"criticism\") appears 1 time.\n",
      "Word 1020 (\"customer\") appears 2 time.\n",
      "Word 1021 (\"decline\") appears 2 time.\n",
      "Word 1022 (\"deserve\") appears 1 time.\n",
      "Word 1023 (\"despite\") appears 2 time.\n",
      "Word 1024 (\"destroy\") appears 1 time.\n",
      "Word 1025 (\"discuss\") appears 2 time.\n",
      "Word 1026 (\"district\") appears 3 time.\n",
      "Word 1027 (\"elect\") appears 1 time.\n",
      "Word 1028 (\"election\") appears 1 time.\n",
      "Word 1029 (\"employee\") appears 1 time.\n",
      "Word 1030 (\"equal\") appears 1 time.\n",
      "Word 1031 (\"executive\") appears 2 time.\n",
      "Word 1032 (\"experience\") appears 4 time.\n",
      "Word 1033 (\"expertise\") appears 2 time.\n",
      "Word 1034 (\"explosion\") appears 2 time.\n",
      "Word 1035 (\"fact\") appears 3 time.\n",
      "Word 1036 (\"fixed\") appears 2 time.\n",
      "Word 1037 (\"forward\") appears 1 time.\n",
      "Word 1038 (\"frankly\") appears 1 time.\n",
      "Word 1039 (\"frost\") appears 3 time.\n",
      "Word 1040 (\"fund\") appears 2 time.\n",
      "Word 1041 (\"gender\") appears 1 time.\n",
      "Word 1042 (\"helping\") appears 1 time.\n",
      "Word 1043 (\"hide\") appears 1 time.\n",
      "Word 1044 (\"historic\") appears 1 time.\n",
      "Word 1045 (\"home\") appears 1 time.\n",
      "Word 1046 (\"howard\") appears 1 time.\n",
      "Word 1047 (\"incident\") appears 2 time.\n",
      "Word 1048 (\"increase\") appears 1 time.\n",
      "Word 1049 (\"increased\") appears 2 time.\n",
      "Word 1050 (\"increasing\") appears 1 time.\n",
      "Word 1051 (\"incumbent\") appears 1 time.\n",
      "Word 1052 (\"infrastructure\") appears 1 time.\n",
      "Word 1053 (\"insight\") appears 1 time.\n",
      "Word 1054 (\"jack\") appears 1 time.\n",
      "Word 1055 (\"january\") appears 2 time.\n",
      "Word 1056 (\"knowledge\") appears 1 time.\n",
      "Word 1057 (\"knowledgeable\") appears 1 time.\n",
      "Word 1058 (\"labor\") appears 1 time.\n",
      "Word 1059 (\"lack\") appears 1 time.\n",
      "Word 1060 (\"lawsuit\") appears 1 time.\n",
      "Word 1061 (\"litigation\") appears 2 time.\n",
      "Word 1062 (\"live\") appears 1 time.\n",
      "Word 1063 (\"market\") appears 4 time.\n",
      "Word 1064 (\"metropolitan\") appears 1 time.\n",
      "Word 1065 (\"mind\") appears 1 time.\n",
      "Word 1066 (\"money\") appears 1 time.\n",
      "Word 1067 (\"monthly\") appears 1 time.\n",
      "Word 1068 (\"natural\") appears 1 time.\n",
      "Word 1069 (\"newcomer\") appears 1 time.\n",
      "Word 1070 (\"northern\") appears 1 time.\n",
      "Word 1071 (\"offset\") appears 1 time.\n",
      "Word 1072 (\"opposition\") appears 1 time.\n",
      "Word 1073 (\"outsource\") appears 1 time.\n",
      "Word 1074 (\"payment\") appears 1 time.\n",
      "Word 1075 (\"pending\") appears 1 time.\n",
      "Word 1076 (\"pension\") appears 1 time.\n",
      "Word 1077 (\"plenty\") appears 1 time.\n",
      "Word 1078 (\"policy-making\") appears 1 time.\n",
      "Word 1079 (\"position\") appears 1 time.\n",
      "Word 1080 (\"president\") appears 1 time.\n",
      "Word 1081 (\"prime\") appears 1 time.\n",
      "Word 1082 (\"provide\") appears 1 time.\n",
      "Word 1083 (\"re-election\") appears 1 time.\n",
      "Word 1084 (\"relative\") appears 1 time.\n",
      "Word 1085 (\"reliance\") appears 1 time.\n",
      "Word 1086 (\"representation\") appears 1 time.\n",
      "Word 1087 (\"revenue\") appears 2 time.\n",
      "Word 1088 (\"role\") appears 1 time.\n",
      "Word 1089 (\"save\") appears 1 time.\n",
      "Word 1090 (\"share\") appears 1 time.\n",
      "Word 1091 (\"shortfall\") appears 1 time.\n",
      "Word 1092 (\"sixth\") appears 1 time.\n",
      "Word 1093 (\"software\") appears 1 time.\n",
      "Word 1094 (\"steer\") appears 1 time.\n",
      "Word 1095 (\"stint\") appears 1 time.\n",
      "Word 1096 (\"street\") appears 1 time.\n",
      "Word 1097 (\"stringent\") appears 1 time.\n",
      "Word 1098 (\"structure\") appears 2 time.\n",
      "Word 1099 (\"subsequent\") appears 1 time.\n",
      "Word 1100 (\"technical\") appears 1 time.\n",
      "Word 1101 (\"term\") appears 1 time.\n",
      "Word 1102 (\"tout\") appears 1 time.\n",
      "Word 1103 (\"transparency\") appears 2 time.\n",
      "Word 1104 (\"transparent\") appears 1 time.\n",
      "Word 1105 (\"two-year\") appears 1 time.\n",
      "Word 1106 (\"unchanged\") appears 1 time.\n",
      "Word 1107 (\"union\") appears 1 time.\n",
      "Word 1108 (\"utility\") appears 9 time.\n",
      "Word 1109 (\"vital\") appears 1 time.\n",
      "Word 1110 (\"volume\") appears 1 time.\n",
      "Word 1111 (\"voter\") appears 1 time.\n",
      "Word 1112 (\"wholesale\") appears 1 time.\n",
      "Word 1113 (\"writer\") appears 1 time.\n",
      "Word 1114 (\"youth\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Check 10th document which word appears how many time, print previous results\n",
    "bow_doc_10 = bow_corpus[10]\n",
    "for i in range(len(bow_doc_10)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_10[i][0], \n",
    "                                               dictionary[bow_doc_10[i][0]],bow_doc_10[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to file\n",
    "bow_corp = pd.DataFrame(bow_corpus)#, columns=['topic_id','words'])\n",
    "#topics.to_csv('results/topics'+fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.13875160249185722),\n",
      " (1, 0.17715031430766318),\n",
      " (2, 0.27721028525058744),\n",
      " (3, 0.12131747497512263),\n",
      " (4, 0.12347796102459174),\n",
      " (5, 0.1891044232255576),\n",
      " (6, 0.13041958050997313),\n",
      " (7, 0.062166725248688805),\n",
      " (8, 0.11560367908079414),\n",
      " (9, 0.12807161883869791),\n",
      " (10, 0.11848732068045718),\n",
      " (11, 0.025903339805993027),\n",
      " (12, 0.2098881712441338),\n",
      " (13, 0.07310700483804931),\n",
      " (14, 0.04553721662579709),\n",
      " (15, 0.0701098956552853),\n",
      " (16, 0.06377944504270776),\n",
      " (17, 0.08063285966758814),\n",
      " (18, 0.26822299077423606),\n",
      " (19, 0.07583102922564613),\n",
      " (20, 0.15614468491195388),\n",
      " (21, 0.20544178170293612),\n",
      " (22, 0.10073535252794036),\n",
      " (23, 0.12570775136353204),\n",
      " (24, 0.16872380372463114),\n",
      " (25, 0.038929328098851024),\n",
      " (26, 0.05031869614151054),\n",
      " (27, 0.17819931852133633),\n",
      " (28, 0.050998930179784505),\n",
      " (29, 0.06073026832316018),\n",
      " (30, 0.06649222693253704),\n",
      " (31, 0.05082413449427594),\n",
      " (32, 0.1494953527134458),\n",
      " (33, 0.04375062855431459),\n",
      " (34, 0.08233282954234428),\n",
      " (35, 0.05537289918246951),\n",
      " (36, 0.21395666957111653),\n",
      " (37, 0.02826045425081141),\n",
      " (38, 0.07388605736031423),\n",
      " (39, 0.07014770790032673),\n",
      " (40, 0.08706930972970299),\n",
      " (41, 0.12184261576733767),\n",
      " (42, 0.06341762854787839),\n",
      " (43, 0.06922917575957259),\n",
      " (44, 0.0710313579747438),\n",
      " (45, 0.15348518392513374),\n",
      " (46, 0.06595285712277416),\n",
      " (47, 0.10405090961109652),\n",
      " (48, 0.21796972211053503),\n",
      " (49, 0.08882224494857036),\n",
      " (50, 0.20544178170293612),\n",
      " (51, 0.09369344977955193),\n",
      " (52, 0.19613156499066747),\n",
      " (53, 0.13565816557001686),\n",
      " (54, 0.08339110012898177),\n",
      " (55, 0.06091282865912503),\n",
      " (56, 0.17112889927354658),\n",
      " (57, 0.10077179528300287),\n",
      " (58, 0.15767660791142038),\n",
      " (59, 0.1309754028548771),\n",
      " (60, 0.036749024503569656),\n",
      " (61, 0.062300930248229684)]\n"
     ]
    }
   ],
   "source": [
    "# TF IDF scores\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step, we create the LDA model to find the topics. We precised 10 topics for now and do 4 passes over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the lda model with gensim providing bow_corpus and dicitonary we created\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=7, id2word=dictionary, passes=4, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.012*\"state\" + 0.008*\"school\" + 0.008*\"people\" + 0.007*\"student\" + 0.005*\"country\" + 0.005*\"university\" + 0.005*\"government\" + 0.004*\"president\" + 0.004*\"vote\" + 0.004*\"group\"\n",
      "Topic: 1 \n",
      "Words: 0.013*\"police\" + 0.011*\"county\" + 0.007*\"city\" + 0.006*\"officer\" + 0.006*\"report\" + 0.005*\"state\" + 0.005*\"department\" + 0.005*\"charge\" + 0.005*\"home\" + 0.005*\"comment\"\n",
      "Topic: 2 \n",
      "Words: 0.007*\"people\" + 0.006*\"know\" + 0.006*\"family\" + 0.006*\"life\" + 0.006*\"woman\" + 0.006*\"child\" + 0.006*\"tell\" + 0.005*\"want\" + 0.005*\"come\" + 0.004*\"think\"\n",
      "Topic: 3 \n",
      "Words: 0.016*\"company\" + 0.010*\"share\" + 0.009*\"million\" + 0.007*\"market\" + 0.007*\"price\" + 0.007*\"stock\" + 0.007*\"business\" + 0.007*\"percent\" + 0.006*\"report\" + 0.006*\"quarter\"\n",
      "Topic: 4 \n",
      "Words: 0.032*\"trump\" + 0.020*\"clinton\" + 0.010*\"election\" + 0.010*\"campaign\" + 0.009*\"republican\" + 0.008*\"e-mail\" + 0.007*\"donald\" + 0.007*\"presidential\" + 0.007*\"hillary\" + 0.006*\"woman\"\n",
      "Topic: 5 \n",
      "Words: 0.005*\"work\" + 0.004*\"people\" + 0.004*\"world\" + 0.004*\"look\" + 0.003*\"know\" + 0.003*\"come\" + 0.003*\"study\" + 0.003*\"thing\" + 0.003*\"need\" + 0.003*\"company\"\n",
      "Topic: 6 \n",
      "Words: 0.024*\"game\" + 0.013*\"play\" + 0.013*\"team\" + 0.011*\"season\" + 0.007*\"player\" + 0.006*\"week\" + 0.006*\"yard\" + 0.006*\"come\" + 0.005*\"second\" + 0.005*\"field\"\n"
     ]
    }
   ],
   "source": [
    "# Print out the find topics most common words\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012*\"state\" + 0.008*\"school\" + 0.008*\"people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.013*\"police\" + 0.011*\"county\" + 0.007*\"city\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.007*\"people\" + 0.006*\"know\" + 0.006*\"family\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016*\"company\" + 0.010*\"share\" + 0.009*\"milli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.032*\"trump\" + 0.020*\"clinton\" + 0.010*\"elect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005*\"work\" + 0.004*\"people\" + 0.004*\"world\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.024*\"game\" + 0.013*\"play\" + 0.013*\"team\" + 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id                                              words\n",
       "0         0  0.012*\"state\" + 0.008*\"school\" + 0.008*\"people...\n",
       "1         1  0.013*\"police\" + 0.011*\"county\" + 0.007*\"city\"...\n",
       "2         2  0.007*\"people\" + 0.006*\"know\" + 0.006*\"family\"...\n",
       "3         3  0.016*\"company\" + 0.010*\"share\" + 0.009*\"milli...\n",
       "4         4  0.032*\"trump\" + 0.020*\"clinton\" + 0.010*\"elect...\n",
       "5         5  0.005*\"work\" + 0.004*\"people\" + 0.004*\"world\" ...\n",
       "6         6  0.024*\"game\" + 0.013*\"play\" + 0.013*\"team\" + 0..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to file\n",
    "topics = pd.DataFrame(lda_model.print_topics(-1), columns=['topic_id','words'])\n",
    "topics.to_csv('results/topics'+fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above topics most common words, we can actually come up with good idea for news topic. For example:\n",
    "- Topic 0: politics/ education\n",
    "- Topic 1: crime\n",
    "- Topic 2: social\n",
    "- Topic 3: business / economy\n",
    "- Topic 4: politics / election\n",
    "- Topic 5: world / ?\n",
    "- Topic 6: sports\n",
    "\n",
    "Looks like we can find some good topics. We will proceed with this approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
