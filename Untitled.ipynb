{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did two data exploration for each dataset separately.\n",
    "\n",
    "### FactBook Dataset\n",
    "\n",
    "Since the dataset is rather small compared to the news data, we downloaded the dataset as json to our local computer. We filtered the data and get only 20 countries that exist in the News on the web dataset.\n",
    "\n",
    "We decided on the useful features of the data that we might possibly find some correlation between the news topics that are extracted from news data.\n",
    "\n",
    "We extracted the features decided on for the specific countries and did some preprocessing to clean the data. \n",
    "Then we created a dataframe that we can easily use for the later work. \n",
    "\n",
    "Afterwards, we get only these features per each country and do the statistical analyses of the data.\n",
    "\n",
    "XXXXX to do clean dataset\n",
    "\n",
    "### Now Corpus Dataset\n",
    "\n",
    "In now corpus dataset have 5 different data file type which are Database, WordLemPoS, Text, Sources, Lexicon. We first downloaded the samples for each of these datafiles and decided to use Sources and WordLemPos since we are interested in finding topics related to each news article. \n",
    "\n",
    "XXX To Do XX hangi attributeleri sectik, hangi fileda, neden\n",
    "xxx clean dataset\n",
    "XXX sources data has managable data size therefore we will directly use this data \n",
    "XXX 1 ay 1 Ã¼lke, time ok but space problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare and Explore Data: Until Nov 11.\n",
    "\n",
    "Understand how to manage the data. \n",
    ".Decide on how to filter the now corpus to have a managable data size.\n",
    ".Decide on which attributes will be taken from Factbook data.\n",
    ".Collect and filter both data.\n",
    "Clean the datasets.\n",
    "Do descriptive statistics and exploration of the data.\n",
    "\n",
    "Enrich Data and Start Analysis: Until Nov 18.\n",
    "\n",
    "Find the topics for each article.\n",
    "Find the tone/sentiment of each article.\n",
    "Find the most frequent X words in each article (excluding stop words).\n",
    "Start doing preliminary analysis of news content.\n",
    "Start doing preliminary analysis of country profiles vs news content.\n",
    "Finalize and Revise the Work done for Milestone 1: Until Nov 25.\n",
    "\n",
    "Finalize preliminary analyses.\n",
    "Revise and comment the code.\n",
    "Decide the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our initial analysis in FactBook dataset, we observed that the features of the countries mostly belongs to 2015 to 2017. Since our aim is to see the correlation between news and factbook data, we decided to use the news belonging to last few years. In order to have a managable datasize, we will first start by using the last year's data and expand our data gradually. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps To Do"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
